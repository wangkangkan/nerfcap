<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>NerfCap: Human Performance Capture withDynamic Neural Radiance Fields</title>
    <!-- Bootstrap -->
    <link href="CSS/bootstrap-4.4.1.css" rel="stylesheet">
    <link rel="stylesheet" href="CSS/font-awesome.min.css">
  </head>
  <div class="containrt">
    <div class="jumbotron text-center" style="margin-bottom:0">
      <h2>NerfCap: Human Performance Capture withDynamic Neural Radiance Fields</h2>
      <hr>
      <h5>Kangkan Wang, Sida Peng, Xiaowei Zhou, Jian Yang, Guofeng Zhang</h5>
      <h5>NANJING UNIVERSITY OF SCIENCE AND TECHNOLOGY</h5>
      <p style="margin-top: 20px;">
        <a class="btn btn-primary" href="https://ieeexplore.ieee.org/abstract/document/9870173"><i class="fa fa-file"></i> Paper</a>
        <a class="btn btn-primary" href="https://github.com/"><i class="fa fa-github"></i> Code</a>
        <a class="btn btn-primary" href="https://ieeexplore.ieee.org/abstract/document/9870173/media#media"><i class="fa fa-video-camera"></i> Video</a>
      </p>
    </div>
  </div>

  <div class="container" style="margin-top:20px;">
    <div class="row">
      <div class="col-sm-4">
        <h3>Abstract</h3>
        <hr>
      </div>
    </div>
    <div class="row">
      <div class="col-12 text-center">
        <img src="img/overview.png" class="img-responsive" style="width: 70%;">
        <p class="text-left">
        This paper addresses the challenge of human performance capture from sparse multi-view or monocular videos. Given a template mesh of the performer, previous methods capture the human motion by non-rigidly registering the template mesh to images with 2D silhouettes or dense photometric alignment. However, the detailed surface deformation cannot be recovered from the silhouettes, while the photometric alignment suffers from instability caused by appearance variation in the videos. To solve these problems, we propose NerfCap, a novel performance capture method based on the dynamic neural radiance field (NeRF) representation of the performer. Specifically, a canonical NeRF is initialized from the template geometry and registered to the video frames by optimizing the deformation field and the appearance model of the canonical NeRF. To capture both large body motion and detailed surface deformation, NerfCap combines linear blend skinning with embedded graph deformation. In contrast to the mesh-based methods that suffer from fixed topology and texture, NerfCap is able to flexibly capture complex geometry and appearance variation across the videos, and synthesize more photo-realistic images. In addition, NerfCap can be pre-trained end to end in a self-supervised manner by matching the synthesized videos with the input videos. Experimental results on various datasets show that NerfCap outperforms prior works in terms of both surface reconstruction accuracy and novel-view synthesis quality.
        </p>
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-xs-4">
        <h3>Result of the Different Dataset</h3>
        <hr>
      </div>
      <div class="col-12 text-center">
        <img src="img/result.png" class="img-responsive" style="width: 80%;">
        <p style="color:#5a6268;">From top to bottom: “FranziRed” and “LingPurple” from DynaCap dataset<br>
        The subject S4 and S1 from DeepCap dataset
        </p>

      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-sm-4">
        <h3>Result of the Dataset</h3>
        <hr>
      </div>
      <div class="col-12 text-center">
        <video controls="controls" width="80%" autoplay="autoplay"  volume="1" id="myVideo"  loop="loop">
          <source id="introduction" src="video/introduction.mp4" type="video/mp4"/>
        </video> 
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row">
      <div class="col-sm-4">
        <h3>Citation</h3>
        <hr>
      </div>
    </div>
    <div class="row">
      <div class="col-12 text-left">
        <p>If you find this code useful for your research, please use the following BibTeX entry.</p>
        <pre style="background-color: #eef0f4; padding-left: 20px;" class="rounded">
          <code>
@ARTICLE{9870173, 
author={Wang, Kangkan and Peng, Sida and Zhou, Xiaowei and Yang, Jian and Zhang, Guofeng},
journal={IEEE Transactions on Visualization and Computer Graphics},   
title={NerfCap: Human Performance Capture With Dynamic Neural Radiance Fields},   
year={2022},  
volume={},  
number={},  
pages={1-13},  
doi={10.1109/TVCG.2022.3202503}}
          </code>
      </pre>
      </div>
    </div>
  </div>
  
</html>